{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b447f4e2",
   "metadata": {},
   "source": [
    "# Model and Settings Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de03b5f",
   "metadata": {},
   "source": [
    "## Comparison of Classification Models and Different Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12fb1f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e583411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turkish Stop Words\n",
    "trstop = [\n",
    "    'a', 'acaba', 'altı', 'altmış', 'ama', 'ancak', 'arada', 'artık', 'asla', 'aslında', 'aslında', 'ayrıca', 'az', 'bana',\n",
    "    'bazen', 'bazı', 'bazıları', 'belki', 'ben', 'benden', 'beni', 'benim', 'beri', 'beş', 'bile', 'bilhassa', 'bin', 'bir',\n",
    "    'biraz', 'birçoğu', 'birçok', 'biri', 'birisi', 'birkaç', 'birşey', 'biz', 'bizden', 'bize', 'bizi', 'bizim', 'böyle',\n",
    "    'böylece', 'bu', 'buna', 'bunda', 'bundan', 'bunlar', 'bunları', 'bunların', 'bunu', 'bunun', 'burada', 'bütün', 'çoğu',\n",
    "    'çoğunu', 'çok', 'çünkü', 'da', 'daha', 'dahi', 'dan', 'de', 'defa', 'değil', 'diğer', 'diğeri', 'diğerleri', 'diye',\n",
    "    'doksan', 'dokuz', 'dolayı', 'dolayısıyla', 'dört', 'e', 'edecek', 'eden', 'ederek', 'edilecek', 'ediliyor', 'edilmesi',\n",
    "    'ediyor', 'eğer', 'elbette', 'elli', 'en', 'etmesi', 'etti', 'ettiği', 'ettiğini', 'fakat', 'falan', 'filan', 'gene',\n",
    "    'gereği', 'gerek', 'gibi', 'göre', 'hala', 'halde', 'halen', 'hangi', 'hangisi', 'hani', 'hatta', 'hem', 'henüz', 'hep',\n",
    "    'hepsi', 'her', 'herhangi', 'herkes', 'herkese', 'herkesi', 'herkesin', 'hiç', 'hiçbir', 'hiçbiri', 'i', 'ı', 'için',\n",
    "    'içinde', 'iki', 'ile', 'ilgili', 'ise', 'işte', 'itibaren', 'itibariyle', 'kaç', 'kadar', 'karşın', 'kendi', 'kendilerine',\n",
    "    'kendine', 'kendini', 'kendisi', 'kendisine', 'kendisini', 'kez', 'ki', 'kim', 'kime', 'kimi', 'kimin', 'kimisi', 'kimse',\n",
    "    'kırk', 'madem', 'mi', 'mı', 'milyar', 'milyon', 'mu', 'mü', 'nasıl', 'ne', 'neden', 'nedenle', 'nerde', 'nerede', 'nereye',\n",
    "    'neyse', 'niçin', 'nin', 'nın', 'niye', 'nun', 'nün', 'o', 'öbür', 'olan', 'olarak', 'oldu', 'olduğu', 'olduğunu',\n",
    "    'olduklarını', 'olmadı', 'olmadığı', 'olmak', 'olması', 'olmayan', 'olmaz', 'olsa', 'olsun', 'olup', 'olur', 'olur',\n",
    "    'olursa', 'oluyor', 'on', 'ön', 'ona', 'önce', 'ondan', 'onlar', 'onlara', 'onlardan', 'onları', 'onların', 'onu', 'onun',\n",
    "    'orada', 'öte', 'ötürü', 'otuz', 'öyle', 'oysa', 'pek', 'rağmen', 'sana', 'sanki', 'sanki', 'şayet', 'şekilde', 'sekiz',\n",
    "    'seksen', 'sen', 'senden', 'seni', 'senin', 'şey', 'şeyden', 'şeye', 'şeyi', 'şeyler', 'şimdi', 'siz', 'siz', 'sizden',\n",
    "    'sizden', 'size', 'sizi', 'sizi', 'sizin', 'sizin', 'sonra', 'şöyle', 'şu', 'şuna', 'şunları', 'şunu', 'ta', 'tabii',\n",
    "    'tam', 'tamam', 'tamamen', 'tarafından', 'trilyon', 'tüm', 'tümü', 'u', 'ü', 'üç', 'un', 'ün', 'üzere', 'var', 'vardı',\n",
    "    've', 'veya', 'ya', 'yani', 'yapacak', 'yapılan', 'yapılması', 'yapıyor', 'yapmak', 'yaptı', 'yaptığı', 'yaptığını',\n",
    "    'yaptıkları', 'ye', 'yedi', 'yerine', 'yetmiş', 'yi', 'yı', 'yine', 'yirmi', 'yoksa', 'yu', 'yüz', 'zaten', 'zira'\n",
    "] # https://github.com/ahmetax/trstop/blob/master/dosyalar/turkce-stop-words\n",
    "\n",
    "nltk_trstop = [\n",
    "    'acaba', 'ama', 'aslında', 'az', 'bazı', 'belki', 'biri', 'birkaç', 'birşey', 'biz', 'bu', 'çok', 'çünkü', 'da', 'daha',\n",
    "    'de', 'defa', 'diye', 'eğer', 'en', 'gibi', 'hem', 'hep', 'hepsi', 'her', 'hiç', 'için', 'ile', 'ise', 'kez', 'ki', 'kim',\n",
    "    'mı', 'mu', 'mü', 'nasıl', 'ne', 'neden', 'nerde', 'nerede', 'nereye', 'niçin', 'niye', 'o', 'sanki', 'şey', 'siz', 'şu',\n",
    "    'tüm', 've', 'veya', 'ya', 'yani'\n",
    "] # https://github.com/xiamx/node-nltk-stopwords/blob/master/data/stopwords/turkish\n",
    "\n",
    "add_stop = [\n",
    "    'a', 'b', 'c', 'ç', 'd', 'e', 'f', 'g', 'ğ', 'h', 'ı', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'ö', 'p', 'r', 's', 'ş', 't',\n",
    "    'u', 'ü', 'v', 'y', 'z', 'li', 'lı', 'si', 'sı', 'te', 'ta', 'ın', 'in', 'na', 'ne', 'ler', 'lar', 'de', 'da', 'nın', 'nin',\n",
    "    'lık', 'ım', 'im', 'yok', 'di', 'dı'\n",
    "]\n",
    "\n",
    "stop_words = sorted(list(set(trstop).union(nltk_trstop).union(add_stop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c1ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read preprocessed data\n",
    "X_preprocessed = pd.read_csv(\"data/X_preprocessed.csv\")[\"full_text\"]\n",
    "X_preprocessed = X_preprocessed.fillna(\"\")\n",
    "X_preprocessed_lemmatized = pd.read_csv(\"data/X_preprocessed_lemmatized.csv\")[\"0\"]\n",
    "X_preprocessed_lemmatized = X_preprocessed_lemmatized.fillna(\"\")\n",
    "y_all = pd.read_csv(\"data/y_all.csv\")[\"label\"]\n",
    "y_final = pd.read_csv(\"data/y_final.csv\")[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e1d2590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_score(feature_extraction_method, stop_words, ngram_range, lemmatization, annotator, classifier):\n",
    "    \"\"\"\n",
    "    Fit your training data to the model of your choice, predict for test data and get F1 score.\n",
    "    Available settings and classifiers:\n",
    "        - feature_extraction_method: \"bow\" (Bag-of-Words) & \"tfidf\" (TF-IDF)\n",
    "        - stop_words: Stop words of your choice as a list\n",
    "        - ngram_range: The lower and upper boundary of the range of n-values for different word n-grams. e.g., (1, 1), (2, 3),...\n",
    "        - lemmatization: True (use lemmatized X) & False (use not lemmatized X)\n",
    "        - annotator: \"final\" (use labels in \"final_annotator\" data set) & \"all\" (use labels in \"all_annotators\" data set)\n",
    "        - classifier: \"logistic regression\", \"multinomial naive bayes\", \"support vector machine\", \"random forest\", \"knn\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Feature extraction method\n",
    "    if feature_extraction_method == \"bow\":\n",
    "        vectorizer = CountVectorizer(stop_words=stop_words, ngram_range=ngram_range)\n",
    "    if feature_extraction_method == \"tfidf\":\n",
    "        vectorizer = TfidfVectorizer(stop_words=stop_words, ngram_range=ngram_range)\n",
    "    \n",
    "    # Lemmatization\n",
    "    if lemmatization:\n",
    "        X = vectorizer.fit_transform(X_preprocessed_lemmatized)\n",
    "    else:\n",
    "        X = vectorizer.fit_transform(X_preprocessed)\n",
    "    \n",
    "    # Annotator\n",
    "    if annotator == \"final\":\n",
    "        y = y_final\n",
    "    if annotator == \"all\":\n",
    "        y = y_all\n",
    "    \n",
    "    # Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=530)\n",
    "    \n",
    "    # Classifier\n",
    "    if classifier == \"logistic regression\":\n",
    "        model = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "    if classifier == \"multinomial naive bayes\":\n",
    "        model = MultinomialNB().fit(X_train, y_train)\n",
    "    if classifier == \"support vector machine\":\n",
    "        model = SVC().fit(X_train, y_train)\n",
    "    if classifier == \"random forest\":\n",
    "        model = RandomForestClassifier().fit(X_train, y_train)\n",
    "    if classifier == \"knn\":\n",
    "        model = KNeighborsClassifier().fit(X_train, y_train)\n",
    "    \n",
    "        \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return f1_score(y_test, y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "631aeba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction_methods = [\"bow\", \"tfidf\"]\n",
    "ngram_ranges = [(1, 1), (1, 2), (1, 3), (2, 2), (2, 3), (3, 3)]\n",
    "lemmatizations = [True, False]\n",
    "annotators = [\"final\", \"all\"]\n",
    "classifiers = [\"logistic regression\", \"multinomial naive bayes\", \"support vector machine\", \"random forest\", \"knn\"]\n",
    "\n",
    "num_combinations = np.prod([len(item) for item in [feature_extraction_methods, ngram_ranges, lemmatizations, annotators, classifiers]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "127dbf3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/240- bow | (1, 1) | True | final | logistic regression | F-1 Score: 0.8784\n",
      "2/240- bow | (1, 1) | True | final | multinomial naive bayes | F-1 Score: 0.8429\n",
      "3/240- bow | (1, 1) | True | final | support vector machine | F-1 Score: 0.8568\n",
      "4/240- bow | (1, 1) | True | final | random forest | F-1 Score: 0.8704\n",
      "5/240- bow | (1, 1) | True | final | knn | F-1 Score: 0.8451\n",
      "6/240- bow | (1, 1) | True | all | logistic regression | F-1 Score: 0.8677\n",
      "7/240- bow | (1, 1) | True | all | multinomial naive bayes | F-1 Score: 0.8314\n",
      "8/240- bow | (1, 1) | True | all | support vector machine | F-1 Score: 0.8445\n",
      "9/240- bow | (1, 1) | True | all | random forest | F-1 Score: 0.8568\n",
      "10/240- bow | (1, 1) | True | all | knn | F-1 Score: 0.8316\n",
      "11/240- bow | (1, 1) | False | final | logistic regression | F-1 Score: 0.8694\n",
      "12/240- bow | (1, 1) | False | final | multinomial naive bayes | F-1 Score: 0.8456\n",
      "13/240- bow | (1, 1) | False | final | support vector machine | F-1 Score: 0.8520\n",
      "14/240- bow | (1, 1) | False | final | random forest | F-1 Score: 0.8658\n",
      "15/240- bow | (1, 1) | False | final | knn | F-1 Score: 0.8407\n",
      "16/240- bow | (1, 1) | False | all | logistic regression | F-1 Score: 0.8574\n",
      "17/240- bow | (1, 1) | False | all | multinomial naive bayes | F-1 Score: 0.8334\n",
      "18/240- bow | (1, 1) | False | all | support vector machine | F-1 Score: 0.8389\n",
      "19/240- bow | (1, 1) | False | all | random forest | F-1 Score: 0.8540\n",
      "20/240- bow | (1, 1) | False | all | knn | F-1 Score: 0.8267\n",
      "21/240- bow | (1, 2) | True | final | logistic regression | F-1 Score: 0.8747\n",
      "22/240- bow | (1, 2) | True | final | multinomial naive bayes | F-1 Score: 0.8460\n",
      "23/240- bow | (1, 2) | True | final | support vector machine | F-1 Score: 0.8494\n",
      "24/240- bow | (1, 2) | True | final | random forest | F-1 Score: 0.8570\n",
      "25/240- bow | (1, 2) | True | final | knn | F-1 Score: 0.8397\n",
      "26/240- bow | (1, 2) | True | all | logistic regression | F-1 Score: 0.8636\n",
      "27/240- bow | (1, 2) | True | all | multinomial naive bayes | F-1 Score: 0.8330\n",
      "28/240- bow | (1, 2) | True | all | support vector machine | F-1 Score: 0.8357\n",
      "29/240- bow | (1, 2) | True | all | random forest | F-1 Score: 0.8453\n",
      "30/240- bow | (1, 2) | True | all | knn | F-1 Score: 0.8257\n",
      "31/240- bow | (1, 2) | False | final | logistic regression | F-1 Score: 0.8626\n",
      "32/240- bow | (1, 2) | False | final | multinomial naive bayes | F-1 Score: 0.8305\n",
      "33/240- bow | (1, 2) | False | final | support vector machine | F-1 Score: 0.8449\n",
      "34/240- bow | (1, 2) | False | final | random forest | F-1 Score: 0.8553\n",
      "35/240- bow | (1, 2) | False | final | knn | F-1 Score: 0.8383\n",
      "36/240- bow | (1, 2) | False | all | logistic regression | F-1 Score: 0.8527\n",
      "37/240- bow | (1, 2) | False | all | multinomial naive bayes | F-1 Score: 0.8236\n",
      "38/240- bow | (1, 2) | False | all | support vector machine | F-1 Score: 0.8306\n",
      "39/240- bow | (1, 2) | False | all | random forest | F-1 Score: 0.8482\n",
      "40/240- bow | (1, 2) | False | all | knn | F-1 Score: 0.8243\n",
      "41/240- bow | (1, 3) | True | final | logistic regression | F-1 Score: 0.8702\n",
      "42/240- bow | (1, 3) | True | final | multinomial naive bayes | F-1 Score: 0.8439\n",
      "43/240- bow | (1, 3) | True | final | support vector machine | F-1 Score: 0.8446\n",
      "44/240- bow | (1, 3) | True | final | random forest | F-1 Score: 0.8550\n",
      "45/240- bow | (1, 3) | True | final | knn | F-1 Score: 0.8384\n",
      "46/240- bow | (1, 3) | True | all | logistic regression | F-1 Score: 0.8606\n",
      "47/240- bow | (1, 3) | True | all | multinomial naive bayes | F-1 Score: 0.8324\n",
      "48/240- bow | (1, 3) | True | all | support vector machine | F-1 Score: 0.8309\n",
      "49/240- bow | (1, 3) | True | all | random forest | F-1 Score: 0.8420\n",
      "50/240- bow | (1, 3) | True | all | knn | F-1 Score: 0.8245\n",
      "51/240- bow | (1, 3) | False | final | logistic regression | F-1 Score: 0.8579\n",
      "52/240- bow | (1, 3) | False | final | multinomial naive bayes | F-1 Score: 0.7700\n",
      "53/240- bow | (1, 3) | False | final | support vector machine | F-1 Score: 0.8424\n",
      "54/240- bow | (1, 3) | False | final | random forest | F-1 Score: 0.8521\n",
      "55/240- bow | (1, 3) | False | final | knn | F-1 Score: 0.8381\n",
      "56/240- bow | (1, 3) | False | all | logistic regression | F-1 Score: 0.8481\n",
      "57/240- bow | (1, 3) | False | all | multinomial naive bayes | F-1 Score: 0.7634\n",
      "58/240- bow | (1, 3) | False | all | support vector machine | F-1 Score: 0.8287\n",
      "59/240- bow | (1, 3) | False | all | random forest | F-1 Score: 0.8394\n",
      "60/240- bow | (1, 3) | False | all | knn | F-1 Score: 0.8241\n",
      "61/240- bow | (2, 2) | True | final | logistic regression | F-1 Score: 0.8479\n",
      "62/240- bow | (2, 2) | True | final | multinomial naive bayes | F-1 Score: 0.6707\n",
      "63/240- bow | (2, 2) | True | final | support vector machine | F-1 Score: 0.8403\n",
      "64/240- bow | (2, 2) | True | final | random forest | F-1 Score: 0.8495\n",
      "65/240- bow | (2, 2) | True | final | knn | F-1 Score: 0.8378\n",
      "66/240- bow | (2, 2) | True | all | logistic regression | F-1 Score: 0.8339\n",
      "67/240- bow | (2, 2) | True | all | multinomial naive bayes | F-1 Score: 0.6643\n",
      "68/240- bow | (2, 2) | True | all | support vector machine | F-1 Score: 0.8263\n",
      "69/240- bow | (2, 2) | True | all | random forest | F-1 Score: 0.8360\n",
      "70/240- bow | (2, 2) | True | all | knn | F-1 Score: 0.8238\n",
      "71/240- bow | (2, 2) | False | final | logistic regression | F-1 Score: 0.8458\n",
      "72/240- bow | (2, 2) | False | final | multinomial naive bayes | F-1 Score: 0.5851\n",
      "73/240- bow | (2, 2) | False | final | support vector machine | F-1 Score: 0.8401\n",
      "74/240- bow | (2, 2) | False | final | random forest | F-1 Score: 0.8479\n",
      "75/240- bow | (2, 2) | False | final | knn | F-1 Score: 0.8378\n",
      "76/240- bow | (2, 2) | False | all | logistic regression | F-1 Score: 0.8323\n",
      "77/240- bow | (2, 2) | False | all | multinomial naive bayes | F-1 Score: 0.5813\n",
      "78/240- bow | (2, 2) | False | all | support vector machine | F-1 Score: 0.8261\n",
      "79/240- bow | (2, 2) | False | all | random forest | F-1 Score: 0.8329\n",
      "80/240- bow | (2, 2) | False | all | knn | F-1 Score: 0.8238\n",
      "81/240- bow | (2, 3) | True | final | logistic regression | F-1 Score: 0.8458\n",
      "82/240- bow | (2, 3) | True | final | multinomial naive bayes | F-1 Score: 0.4252\n",
      "83/240- bow | (2, 3) | True | final | support vector machine | F-1 Score: 0.8382\n",
      "84/240- bow | (2, 3) | True | final | random forest | F-1 Score: 0.8485\n",
      "85/240- bow | (2, 3) | True | final | knn | F-1 Score: 0.8372\n",
      "86/240- bow | (2, 3) | True | all | logistic regression | F-1 Score: 0.8317\n",
      "87/240- bow | (2, 3) | True | all | multinomial naive bayes | F-1 Score: 0.4228\n",
      "88/240- bow | (2, 3) | True | all | support vector machine | F-1 Score: 0.8242\n",
      "89/240- bow | (2, 3) | True | all | random forest | F-1 Score: 0.8351\n",
      "90/240- bow | (2, 3) | True | all | knn | F-1 Score: 0.8233\n",
      "91/240- bow | (2, 3) | False | final | logistic regression | F-1 Score: 0.8434\n",
      "92/240- bow | (2, 3) | False | final | multinomial naive bayes | F-1 Score: 0.3389\n",
      "93/240- bow | (2, 3) | False | final | support vector machine | F-1 Score: 0.8382\n",
      "94/240- bow | (2, 3) | False | final | random forest | F-1 Score: 0.8461\n",
      "95/240- bow | (2, 3) | False | final | knn | F-1 Score: 0.8369\n",
      "96/240- bow | (2, 3) | False | all | logistic regression | F-1 Score: 0.8294\n",
      "97/240- bow | (2, 3) | False | all | multinomial naive bayes | F-1 Score: 0.3375\n",
      "98/240- bow | (2, 3) | False | all | support vector machine | F-1 Score: 0.8242\n",
      "99/240- bow | (2, 3) | False | all | random forest | F-1 Score: 0.8321\n",
      "100/240- bow | (2, 3) | False | all | knn | F-1 Score: 0.8229\n",
      "101/240- bow | (3, 3) | True | final | logistic regression | F-1 Score: 0.8400\n",
      "102/240- bow | (3, 3) | True | final | multinomial naive bayes | F-1 Score: 0.5661\n",
      "103/240- bow | (3, 3) | True | final | support vector machine | F-1 Score: 0.8366\n",
      "104/240- bow | (3, 3) | True | final | random forest | F-1 Score: 0.8438\n",
      "105/240- bow | (3, 3) | True | final | knn | F-1 Score: 0.8367\n",
      "106/240- bow | (3, 3) | True | all | logistic regression | F-1 Score: 0.8260\n",
      "107/240- bow | (3, 3) | True | all | multinomial naive bayes | F-1 Score: 0.5618\n",
      "108/240- bow | (3, 3) | True | all | support vector machine | F-1 Score: 0.8227\n",
      "109/240- bow | (3, 3) | True | all | random forest | F-1 Score: 0.8301\n",
      "110/240- bow | (3, 3) | True | all | knn | F-1 Score: 0.8227\n",
      "111/240- bow | (3, 3) | False | final | logistic regression | F-1 Score: 0.8388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/240- bow | (3, 3) | False | final | multinomial naive bayes | F-1 Score: 0.5445\n",
      "113/240- bow | (3, 3) | False | final | support vector machine | F-1 Score: 0.8364\n",
      "114/240- bow | (3, 3) | False | final | random forest | F-1 Score: 0.8428\n",
      "115/240- bow | (3, 3) | False | final | knn | F-1 Score: 0.8367\n",
      "116/240- bow | (3, 3) | False | all | logistic regression | F-1 Score: 0.8247\n",
      "117/240- bow | (3, 3) | False | all | multinomial naive bayes | F-1 Score: 0.5412\n",
      "118/240- bow | (3, 3) | False | all | support vector machine | F-1 Score: 0.8224\n",
      "119/240- bow | (3, 3) | False | all | random forest | F-1 Score: 0.8290\n",
      "120/240- bow | (3, 3) | False | all | knn | F-1 Score: 0.8227\n",
      "121/240- tfidf | (1, 1) | True | final | logistic regression | F-1 Score: 0.8613\n",
      "122/240- tfidf | (1, 1) | True | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "123/240- tfidf | (1, 1) | True | final | support vector machine | F-1 Score: 0.8565\n",
      "124/240- tfidf | (1, 1) | True | final | random forest | F-1 Score: 0.8644\n",
      "125/240- tfidf | (1, 1) | True | final | knn | F-1 Score: 0.8406\n",
      "126/240- tfidf | (1, 1) | True | all | logistic regression | F-1 Score: 0.8487\n",
      "127/240- tfidf | (1, 1) | True | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "128/240- tfidf | (1, 1) | True | all | support vector machine | F-1 Score: 0.8445\n",
      "129/240- tfidf | (1, 1) | True | all | random forest | F-1 Score: 0.8524\n",
      "130/240- tfidf | (1, 1) | True | all | knn | F-1 Score: 0.8266\n",
      "131/240- tfidf | (1, 1) | False | final | logistic regression | F-1 Score: 0.8488\n",
      "132/240- tfidf | (1, 1) | False | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "133/240- tfidf | (1, 1) | False | final | support vector machine | F-1 Score: 0.8484\n",
      "134/240- tfidf | (1, 1) | False | final | random forest | F-1 Score: 0.8596\n",
      "135/240- tfidf | (1, 1) | False | final | knn | F-1 Score: 0.8383\n",
      "136/240- tfidf | (1, 1) | False | all | logistic regression | F-1 Score: 0.8354\n",
      "137/240- tfidf | (1, 1) | False | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "138/240- tfidf | (1, 1) | False | all | support vector machine | F-1 Score: 0.8347\n",
      "139/240- tfidf | (1, 1) | False | all | random forest | F-1 Score: 0.8468\n",
      "140/240- tfidf | (1, 1) | False | all | knn | F-1 Score: 0.8244\n",
      "141/240- tfidf | (1, 2) | True | final | logistic regression | F-1 Score: 0.8506\n",
      "142/240- tfidf | (1, 2) | True | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "143/240- tfidf | (1, 2) | True | final | support vector machine | F-1 Score: 0.8485\n",
      "144/240- tfidf | (1, 2) | True | final | random forest | F-1 Score: 0.8554\n",
      "145/240- tfidf | (1, 2) | True | final | knn | F-1 Score: 0.8381\n",
      "146/240- tfidf | (1, 2) | True | all | logistic regression | F-1 Score: 0.8368\n",
      "147/240- tfidf | (1, 2) | True | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "148/240- tfidf | (1, 2) | True | all | support vector machine | F-1 Score: 0.8351\n",
      "149/240- tfidf | (1, 2) | True | all | random forest | F-1 Score: 0.8404\n",
      "150/240- tfidf | (1, 2) | True | all | knn | F-1 Score: 0.8241\n",
      "151/240- tfidf | (1, 2) | False | final | logistic regression | F-1 Score: 0.8448\n",
      "152/240- tfidf | (1, 2) | False | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "153/240- tfidf | (1, 2) | False | final | support vector machine | F-1 Score: 0.8430\n",
      "154/240- tfidf | (1, 2) | False | final | random forest | F-1 Score: 0.8552\n",
      "155/240- tfidf | (1, 2) | False | final | knn | F-1 Score: 0.8377\n",
      "156/240- tfidf | (1, 2) | False | all | logistic regression | F-1 Score: 0.8308\n",
      "157/240- tfidf | (1, 2) | False | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "158/240- tfidf | (1, 2) | False | all | support vector machine | F-1 Score: 0.8290\n",
      "159/240- tfidf | (1, 2) | False | all | random forest | F-1 Score: 0.8431\n",
      "160/240- tfidf | (1, 2) | False | all | knn | F-1 Score: 0.8238\n",
      "161/240- tfidf | (1, 3) | True | final | logistic regression | F-1 Score: 0.8455\n",
      "162/240- tfidf | (1, 3) | True | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "163/240- tfidf | (1, 3) | True | final | support vector machine | F-1 Score: 0.8422\n",
      "164/240- tfidf | (1, 3) | True | final | random forest | F-1 Score: 0.8529\n",
      "165/240- tfidf | (1, 3) | True | final | knn | F-1 Score: 0.8378\n",
      "166/240- tfidf | (1, 3) | True | all | logistic regression | F-1 Score: 0.8321\n",
      "167/240- tfidf | (1, 3) | True | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "168/240- tfidf | (1, 3) | True | all | support vector machine | F-1 Score: 0.8288\n",
      "169/240- tfidf | (1, 3) | True | all | random forest | F-1 Score: 0.8369\n",
      "170/240- tfidf | (1, 3) | True | all | knn | F-1 Score: 0.8238\n",
      "171/240- tfidf | (1, 3) | False | final | logistic regression | F-1 Score: 0.8413\n",
      "172/240- tfidf | (1, 3) | False | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "173/240- tfidf | (1, 3) | False | final | support vector machine | F-1 Score: 0.8411\n",
      "174/240- tfidf | (1, 3) | False | final | random forest | F-1 Score: 0.8494\n",
      "175/240- tfidf | (1, 3) | False | final | knn | F-1 Score: 0.8378\n",
      "176/240- tfidf | (1, 3) | False | all | logistic regression | F-1 Score: 0.8276\n",
      "177/240- tfidf | (1, 3) | False | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "178/240- tfidf | (1, 3) | False | all | support vector machine | F-1 Score: 0.8271\n",
      "179/240- tfidf | (1, 3) | False | all | random forest | F-1 Score: 0.8389\n",
      "180/240- tfidf | (1, 3) | False | all | knn | F-1 Score: 0.8238\n",
      "181/240- tfidf | (2, 2) | True | final | logistic regression | F-1 Score: 0.8398\n",
      "182/240- tfidf | (2, 2) | True | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "183/240- tfidf | (2, 2) | True | final | support vector machine | F-1 Score: 0.8408\n",
      "184/240- tfidf | (2, 2) | True | final | random forest | F-1 Score: 0.8495\n",
      "185/240- tfidf | (2, 2) | True | final | knn | F-1 Score: 0.8378\n",
      "186/240- tfidf | (2, 2) | True | all | logistic regression | F-1 Score: 0.8258\n",
      "187/240- tfidf | (2, 2) | True | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "188/240- tfidf | (2, 2) | True | all | support vector machine | F-1 Score: 0.8268\n",
      "189/240- tfidf | (2, 2) | True | all | random forest | F-1 Score: 0.8373\n",
      "190/240- tfidf | (2, 2) | True | all | knn | F-1 Score: 0.8238\n",
      "191/240- tfidf | (2, 2) | False | final | logistic regression | F-1 Score: 0.8395\n",
      "192/240- tfidf | (2, 2) | False | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "193/240- tfidf | (2, 2) | False | final | support vector machine | F-1 Score: 0.8399\n",
      "194/240- tfidf | (2, 2) | False | final | random forest | F-1 Score: 0.8459\n",
      "195/240- tfidf | (2, 2) | False | final | knn | F-1 Score: 0.8378\n",
      "196/240- tfidf | (2, 2) | False | all | logistic regression | F-1 Score: 0.8256\n",
      "197/240- tfidf | (2, 2) | False | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "198/240- tfidf | (2, 2) | False | all | support vector machine | F-1 Score: 0.8259\n",
      "199/240- tfidf | (2, 2) | False | all | random forest | F-1 Score: 0.8322\n",
      "200/240- tfidf | (2, 2) | False | all | knn | F-1 Score: 0.8238\n",
      "201/240- tfidf | (2, 3) | True | final | logistic regression | F-1 Score: 0.8389\n",
      "202/240- tfidf | (2, 3) | True | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "203/240- tfidf | (2, 3) | True | final | support vector machine | F-1 Score: 0.8390\n",
      "204/240- tfidf | (2, 3) | True | final | random forest | F-1 Score: 0.8483\n",
      "205/240- tfidf | (2, 3) | True | final | knn | F-1 Score: 0.8372\n",
      "206/240- tfidf | (2, 3) | True | all | logistic regression | F-1 Score: 0.8250\n",
      "207/240- tfidf | (2, 3) | True | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "208/240- tfidf | (2, 3) | True | all | support vector machine | F-1 Score: 0.8250\n",
      "209/240- tfidf | (2, 3) | True | all | random forest | F-1 Score: 0.8343\n",
      "210/240- tfidf | (2, 3) | True | all | knn | F-1 Score: 0.8232\n",
      "211/240- tfidf | (2, 3) | False | final | logistic regression | F-1 Score: 0.8383\n",
      "212/240- tfidf | (2, 3) | False | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "213/240- tfidf | (2, 3) | False | final | support vector machine | F-1 Score: 0.8387\n",
      "214/240- tfidf | (2, 3) | False | final | random forest | F-1 Score: 0.8465\n",
      "215/240- tfidf | (2, 3) | False | final | knn | F-1 Score: 0.8373\n",
      "216/240- tfidf | (2, 3) | False | all | logistic regression | F-1 Score: 0.8244\n",
      "217/240- tfidf | (2, 3) | False | all | multinomial naive bayes | F-1 Score: 0.8224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/240- tfidf | (2, 3) | False | all | support vector machine | F-1 Score: 0.8247\n",
      "219/240- tfidf | (2, 3) | False | all | random forest | F-1 Score: 0.8311\n",
      "220/240- tfidf | (2, 3) | False | all | knn | F-1 Score: 0.8233\n",
      "221/240- tfidf | (3, 3) | True | final | logistic regression | F-1 Score: 0.8373\n",
      "222/240- tfidf | (3, 3) | True | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "223/240- tfidf | (3, 3) | True | final | support vector machine | F-1 Score: 0.8379\n",
      "224/240- tfidf | (3, 3) | True | final | random forest | F-1 Score: 0.8433\n",
      "225/240- tfidf | (3, 3) | True | final | knn | F-1 Score: 0.8373\n",
      "226/240- tfidf | (3, 3) | True | all | logistic regression | F-1 Score: 0.8233\n",
      "227/240- tfidf | (3, 3) | True | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "228/240- tfidf | (3, 3) | True | all | support vector machine | F-1 Score: 0.8239\n",
      "229/240- tfidf | (3, 3) | True | all | random forest | F-1 Score: 0.8293\n",
      "230/240- tfidf | (3, 3) | True | all | knn | F-1 Score: 0.8233\n",
      "231/240- tfidf | (3, 3) | False | final | logistic regression | F-1 Score: 0.8373\n",
      "232/240- tfidf | (3, 3) | False | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "233/240- tfidf | (3, 3) | False | final | support vector machine | F-1 Score: 0.8379\n",
      "234/240- tfidf | (3, 3) | False | final | random forest | F-1 Score: 0.8422\n",
      "235/240- tfidf | (3, 3) | False | final | knn | F-1 Score: 0.8373\n",
      "236/240- tfidf | (3, 3) | False | all | logistic regression | F-1 Score: 0.8233\n",
      "237/240- tfidf | (3, 3) | False | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "238/240- tfidf | (3, 3) | False | all | support vector machine | F-1 Score: 0.8239\n",
      "239/240- tfidf | (3, 3) | False | all | random forest | F-1 Score: 0.8292\n",
      "240/240- tfidf | (3, 3) | False | all | knn | F-1 Score: 0.8233\n",
      "\n",
      "Comparison of classification models and different settings took 1379.62 minutes.\n"
     ]
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(columns = [\"feature_extraction_method\", \"ngram_range\", \"lemmatization\", \"annotator\", \"model\", \"f1_score\"])\n",
    "\n",
    "i = 0\n",
    "\n",
    "start_time = time.time()\n",
    "for feature_extraction_method in feature_extraction_methods:\n",
    "    for ngram_range in ngram_ranges:\n",
    "        for lemmatization in lemmatizations:\n",
    "            for annotator in annotators:\n",
    "                for classifier in classifiers:\n",
    "                    print(f\"{i+1}/{num_combinations}- {feature_extraction_method} | {ngram_range} | {lemmatization} | {annotator} | {classifier} | F-1 Score: {fit_predict_score(feature_extraction_method, stop_words, ngram_range, lemmatization, annotator, classifier):.4f}\")\n",
    "                    scores_df = scores_df.append(pd.Series([feature_extraction_method,\n",
    "                                                            ngram_range,\n",
    "                                                            lemmatization,\n",
    "                                                            annotator,\n",
    "                                                            classifier,\n",
    "                                                            fit_predict_score(feature_extraction_method,\n",
    "                                                                              stop_words,\n",
    "                                                                              ngram_range,\n",
    "                                                                              lemmatization,\n",
    "                                                                              annotator,\n",
    "                                                                              classifier)],\n",
    "                                                           index=scores_df.columns),\n",
    "                                                 ignore_index=True)\n",
    "                    i = i + 1\n",
    "\n",
    "print(f\"\\nComparison of classification models and different settings took {(time.time() - start_time)/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ca37e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_extraction_method</th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>lemmatization</th>\n",
       "      <th>annotator</th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.878366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.842941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>support vector machine</td>\n",
       "      <td>0.856846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.870077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.845095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature_extraction_method ngram_range  lemmatization annotator  \\\n",
       "0                       bow      (1, 1)           True     final   \n",
       "1                       bow      (1, 1)           True     final   \n",
       "2                       bow      (1, 1)           True     final   \n",
       "3                       bow      (1, 1)           True     final   \n",
       "4                       bow      (1, 1)           True     final   \n",
       "\n",
       "                     model  f1_score  \n",
       "0      logistic regression  0.878366  \n",
       "1  multinomial naive bayes  0.842941  \n",
       "2   support vector machine  0.856846  \n",
       "3            random forest  0.870077  \n",
       "4                      knn  0.845095  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "092f4219",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_extraction_method</th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>lemmatization</th>\n",
       "      <th>annotator</th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.878366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.874668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.870230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.870077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.869353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>all</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.867650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>all</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.863566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.863404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.862634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.862226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.862220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.861266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>all</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.860631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.857898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.857366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>support vector machine</td>\n",
       "      <td>0.856846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>support vector machine</td>\n",
       "      <td>0.856498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>all</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.855877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.855860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.855529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.854982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.853324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.853197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.852849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.852657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>support vector machine</td>\n",
       "      <td>0.851999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.851846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.851706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.850584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>bow</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.849761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_extraction_method ngram_range  lemmatization annotator  \\\n",
       "0                         bow      (1, 1)           True     final   \n",
       "20                        bow      (1, 2)           True     final   \n",
       "40                        bow      (1, 3)           True     final   \n",
       "3                         bow      (1, 1)           True     final   \n",
       "10                        bow      (1, 1)          False     final   \n",
       "5                         bow      (1, 1)           True       all   \n",
       "25                        bow      (1, 2)           True       all   \n",
       "13                        bow      (1, 1)          False     final   \n",
       "30                        bow      (1, 2)          False     final   \n",
       "123                     tfidf      (1, 1)           True     final   \n",
       "133                     tfidf      (1, 1)          False     final   \n",
       "120                     tfidf      (1, 1)           True     final   \n",
       "45                        bow      (1, 3)           True       all   \n",
       "50                        bow      (1, 3)          False     final   \n",
       "15                        bow      (1, 1)          False       all   \n",
       "2                         bow      (1, 1)           True     final   \n",
       "122                     tfidf      (1, 1)           True     final   \n",
       "8                         bow      (1, 1)           True       all   \n",
       "143                     tfidf      (1, 2)           True     final   \n",
       "33                        bow      (1, 2)          False     final   \n",
       "23                        bow      (1, 2)           True     final   \n",
       "53                        bow      (1, 3)          False     final   \n",
       "43                        bow      (1, 3)           True     final   \n",
       "18                        bow      (1, 1)          False       all   \n",
       "35                        bow      (1, 2)          False       all   \n",
       "12                        bow      (1, 1)          False     final   \n",
       "153                     tfidf      (1, 2)          False     final   \n",
       "163                     tfidf      (1, 3)           True     final   \n",
       "140                     tfidf      (1, 2)           True     final   \n",
       "63                        bow      (2, 2)           True     final   \n",
       "\n",
       "                      model  f1_score  \n",
       "0       logistic regression  0.878366  \n",
       "20      logistic regression  0.874668  \n",
       "40      logistic regression  0.870230  \n",
       "3             random forest  0.870077  \n",
       "10      logistic regression  0.869353  \n",
       "5       logistic regression  0.867650  \n",
       "25      logistic regression  0.863566  \n",
       "13            random forest  0.863404  \n",
       "30      logistic regression  0.862634  \n",
       "123           random forest  0.862226  \n",
       "133           random forest  0.862220  \n",
       "120     logistic regression  0.861266  \n",
       "45      logistic regression  0.860631  \n",
       "50      logistic regression  0.857898  \n",
       "15      logistic regression  0.857366  \n",
       "2    support vector machine  0.856846  \n",
       "122  support vector machine  0.856498  \n",
       "8             random forest  0.855877  \n",
       "143           random forest  0.855860  \n",
       "33            random forest  0.855529  \n",
       "23            random forest  0.854982  \n",
       "53            random forest  0.853324  \n",
       "43            random forest  0.853197  \n",
       "18            random forest  0.852849  \n",
       "35      logistic regression  0.852657  \n",
       "12   support vector machine  0.851999  \n",
       "153           random forest  0.851846  \n",
       "163           random forest  0.851706  \n",
       "140     logistic regression  0.850584  \n",
       "63            random forest  0.849761  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values(\"f1_score\", ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b4ef6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_extraction_method</th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>lemmatization</th>\n",
       "      <th>annotator</th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>bow</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>all</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.822708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>bow</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.822708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>bow</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>all</td>\n",
       "      <td>support vector machine</td>\n",
       "      <td>0.822652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.822402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>bow</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>support vector machine</td>\n",
       "      <td>0.822402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.822402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.822402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.822402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.822402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.822402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.822402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.822402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.822402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.822402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.822402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.822402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.769959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.763428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>bow</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.670739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>bow</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.664303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>bow</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.585101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>bow</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.581327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>bow</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.566102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>bow</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.561829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>bow</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.544505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>bow</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.541242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>bow</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.425245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>bow</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.422793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>bow</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.338942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>bow</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.337530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_extraction_method ngram_range  lemmatization annotator  \\\n",
       "109                       bow      (3, 3)           True       all   \n",
       "119                       bow      (3, 3)          False       all   \n",
       "107                       bow      (3, 3)           True       all   \n",
       "206                     tfidf      (2, 3)           True       all   \n",
       "117                       bow      (3, 3)          False       all   \n",
       "236                     tfidf      (3, 3)          False       all   \n",
       "226                     tfidf      (3, 3)           True       all   \n",
       "196                     tfidf      (2, 2)          False       all   \n",
       "126                     tfidf      (1, 1)           True       all   \n",
       "176                     tfidf      (1, 3)          False       all   \n",
       "216                     tfidf      (2, 3)          False       all   \n",
       "136                     tfidf      (1, 1)          False       all   \n",
       "146                     tfidf      (1, 2)           True       all   \n",
       "156                     tfidf      (1, 2)          False       all   \n",
       "166                     tfidf      (1, 3)           True       all   \n",
       "186                     tfidf      (2, 2)           True       all   \n",
       "51                        bow      (1, 3)          False     final   \n",
       "56                        bow      (1, 3)          False       all   \n",
       "61                        bow      (2, 2)           True     final   \n",
       "66                        bow      (2, 2)           True       all   \n",
       "71                        bow      (2, 2)          False     final   \n",
       "76                        bow      (2, 2)          False       all   \n",
       "101                       bow      (3, 3)           True     final   \n",
       "106                       bow      (3, 3)           True       all   \n",
       "111                       bow      (3, 3)          False     final   \n",
       "116                       bow      (3, 3)          False       all   \n",
       "81                        bow      (2, 3)           True     final   \n",
       "86                        bow      (2, 3)           True       all   \n",
       "91                        bow      (2, 3)          False     final   \n",
       "96                        bow      (2, 3)          False       all   \n",
       "\n",
       "                       model  f1_score  \n",
       "109                      knn  0.822708  \n",
       "119                      knn  0.822708  \n",
       "107   support vector machine  0.822652  \n",
       "206  multinomial naive bayes  0.822402  \n",
       "117   support vector machine  0.822402  \n",
       "236  multinomial naive bayes  0.822402  \n",
       "226  multinomial naive bayes  0.822402  \n",
       "196  multinomial naive bayes  0.822402  \n",
       "126  multinomial naive bayes  0.822402  \n",
       "176  multinomial naive bayes  0.822402  \n",
       "216  multinomial naive bayes  0.822402  \n",
       "136  multinomial naive bayes  0.822402  \n",
       "146  multinomial naive bayes  0.822402  \n",
       "156  multinomial naive bayes  0.822402  \n",
       "166  multinomial naive bayes  0.822402  \n",
       "186  multinomial naive bayes  0.822402  \n",
       "51   multinomial naive bayes  0.769959  \n",
       "56   multinomial naive bayes  0.763428  \n",
       "61   multinomial naive bayes  0.670739  \n",
       "66   multinomial naive bayes  0.664303  \n",
       "71   multinomial naive bayes  0.585101  \n",
       "76   multinomial naive bayes  0.581327  \n",
       "101  multinomial naive bayes  0.566102  \n",
       "106  multinomial naive bayes  0.561829  \n",
       "111  multinomial naive bayes  0.544505  \n",
       "116  multinomial naive bayes  0.541242  \n",
       "81   multinomial naive bayes  0.425245  \n",
       "86   multinomial naive bayes  0.422793  \n",
       "91   multinomial naive bayes  0.338942  \n",
       "96   multinomial naive bayes  0.337530  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values(\"f1_score\", ascending=False).tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b5d30ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.to_csv(\"data/scores.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
