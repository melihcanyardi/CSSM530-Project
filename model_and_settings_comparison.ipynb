{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b447f4e2",
   "metadata": {},
   "source": [
    "# Model and Settings Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de03b5f",
   "metadata": {},
   "source": [
    "## Comparison of Classification Models and Different Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12fb1f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e583411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turkish Stop Words\n",
    "trstop = [\n",
    "    'a', 'acaba', 'altı', 'altmış', 'ama', 'ancak', 'arada', 'artık', 'asla', 'aslında', 'aslında', 'ayrıca', 'az', 'bana',\n",
    "    'bazen', 'bazı', 'bazıları', 'belki', 'ben', 'benden', 'beni', 'benim', 'beri', 'beş', 'bile', 'bilhassa', 'bin', 'bir',\n",
    "    'biraz', 'birçoğu', 'birçok', 'biri', 'birisi', 'birkaç', 'birşey', 'biz', 'bizden', 'bize', 'bizi', 'bizim', 'böyle',\n",
    "    'böylece', 'bu', 'buna', 'bunda', 'bundan', 'bunlar', 'bunları', 'bunların', 'bunu', 'bunun', 'burada', 'bütün', 'çoğu',\n",
    "    'çoğunu', 'çok', 'çünkü', 'da', 'daha', 'dahi', 'dan', 'de', 'defa', 'değil', 'diğer', 'diğeri', 'diğerleri', 'diye',\n",
    "    'doksan', 'dokuz', 'dolayı', 'dolayısıyla', 'dört', 'e', 'edecek', 'eden', 'ederek', 'edilecek', 'ediliyor', 'edilmesi',\n",
    "    'ediyor', 'eğer', 'elbette', 'elli', 'en', 'etmesi', 'etti', 'ettiği', 'ettiğini', 'fakat', 'falan', 'filan', 'gene',\n",
    "    'gereği', 'gerek', 'gibi', 'göre', 'hala', 'halde', 'halen', 'hangi', 'hangisi', 'hani', 'hatta', 'hem', 'henüz', 'hep',\n",
    "    'hepsi', 'her', 'herhangi', 'herkes', 'herkese', 'herkesi', 'herkesin', 'hiç', 'hiçbir', 'hiçbiri', 'i', 'ı', 'için',\n",
    "    'içinde', 'iki', 'ile', 'ilgili', 'ise', 'işte', 'itibaren', 'itibariyle', 'kaç', 'kadar', 'karşın', 'kendi', 'kendilerine',\n",
    "    'kendine', 'kendini', 'kendisi', 'kendisine', 'kendisini', 'kez', 'ki', 'kim', 'kime', 'kimi', 'kimin', 'kimisi', 'kimse',\n",
    "    'kırk', 'madem', 'mi', 'mı', 'milyar', 'milyon', 'mu', 'mü', 'nasıl', 'ne', 'neden', 'nedenle', 'nerde', 'nerede', 'nereye',\n",
    "    'neyse', 'niçin', 'nin', 'nın', 'niye', 'nun', 'nün', 'o', 'öbür', 'olan', 'olarak', 'oldu', 'olduğu', 'olduğunu',\n",
    "    'olduklarını', 'olmadı', 'olmadığı', 'olmak', 'olması', 'olmayan', 'olmaz', 'olsa', 'olsun', 'olup', 'olur', 'olur',\n",
    "    'olursa', 'oluyor', 'on', 'ön', 'ona', 'önce', 'ondan', 'onlar', 'onlara', 'onlardan', 'onları', 'onların', 'onu', 'onun',\n",
    "    'orada', 'öte', 'ötürü', 'otuz', 'öyle', 'oysa', 'pek', 'rağmen', 'sana', 'sanki', 'sanki', 'şayet', 'şekilde', 'sekiz',\n",
    "    'seksen', 'sen', 'senden', 'seni', 'senin', 'şey', 'şeyden', 'şeye', 'şeyi', 'şeyler', 'şimdi', 'siz', 'siz', 'sizden',\n",
    "    'sizden', 'size', 'sizi', 'sizi', 'sizin', 'sizin', 'sonra', 'şöyle', 'şu', 'şuna', 'şunları', 'şunu', 'ta', 'tabii',\n",
    "    'tam', 'tamam', 'tamamen', 'tarafından', 'trilyon', 'tüm', 'tümü', 'u', 'ü', 'üç', 'un', 'ün', 'üzere', 'var', 'vardı',\n",
    "    've', 'veya', 'ya', 'yani', 'yapacak', 'yapılan', 'yapılması', 'yapıyor', 'yapmak', 'yaptı', 'yaptığı', 'yaptığını',\n",
    "    'yaptıkları', 'ye', 'yedi', 'yerine', 'yetmiş', 'yi', 'yı', 'yine', 'yirmi', 'yoksa', 'yu', 'yüz', 'zaten', 'zira'\n",
    "] # https://github.com/ahmetax/trstop/blob/master/dosyalar/turkce-stop-words\n",
    "\n",
    "nltk_trstop = [\n",
    "    'acaba', 'ama', 'aslında', 'az', 'bazı', 'belki', 'biri', 'birkaç', 'birşey', 'biz', 'bu', 'çok', 'çünkü', 'da', 'daha',\n",
    "    'de', 'defa', 'diye', 'eğer', 'en', 'gibi', 'hem', 'hep', 'hepsi', 'her', 'hiç', 'için', 'ile', 'ise', 'kez', 'ki', 'kim',\n",
    "    'mı', 'mu', 'mü', 'nasıl', 'ne', 'neden', 'nerde', 'nerede', 'nereye', 'niçin', 'niye', 'o', 'sanki', 'şey', 'siz', 'şu',\n",
    "    'tüm', 've', 'veya', 'ya', 'yani'\n",
    "] # https://github.com/xiamx/node-nltk-stopwords/blob/master/data/stopwords/turkish\n",
    "\n",
    "add_stop = [\n",
    "    'a', 'b', 'c', 'ç', 'd', 'e', 'f', 'g', 'ğ', 'h', 'ı', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'ö', 'p', 'r', 's', 'ş', 't',\n",
    "    'u', 'ü', 'v', 'y', 'z', 'li', 'lı', 'si', 'sı', 'te', 'ta', 'ın', 'in', 'na', 'ne', 'ler', 'lar', 'de', 'da', 'nın', 'nin',\n",
    "    'lık', 'ım', 'im', 'yok', 'di', 'dı'\n",
    "]\n",
    "\n",
    "stop_words = sorted(list(set(trstop).union(nltk_trstop).union(add_stop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c1ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read preprocessed data\n",
    "X_preprocessed = pd.read_csv(\"data/X_preprocessed.csv\")[\"full_text\"]\n",
    "X_preprocessed = X_preprocessed.fillna(\"\")\n",
    "X_preprocessed_lemmatized = pd.read_csv(\"data/X_preprocessed_lemmatized.csv\")[\"0\"]\n",
    "X_preprocessed_lemmatized = X_preprocessed_lemmatized.fillna(\"\")\n",
    "y_all = pd.read_csv(\"data/y_all.csv\")[\"label\"]\n",
    "y_final = pd.read_csv(\"data/y_final.csv\")[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e1d2590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_score(feature_extraction_method, stop_words, ngram_range, lemmatization, annotator, classifier):\n",
    "    \"\"\"\n",
    "    Fit your training data to the model of your choice, predict for test data and get F1 score.\n",
    "    Available settings and classifiers:\n",
    "        - feature_extraction_method: \"bow\" (Bag-of-Words) & \"tfidf\" (TF-IDF)\n",
    "        - stop_words: Stop words of your choice as a list\n",
    "        - ngram_range: The lower and upper boundary of the range of n-values for different word n-grams. e.g., (1, 1), (2, 3),...\n",
    "        - lemmatization: True (use lemmatized X) & False (use not lemmatized X)\n",
    "        - annotator: \"final\" (use labels in \"final_annotator\" data set) & \"all\" (use labels in \"all_annotators\" data set)\n",
    "        - classifier: \"logistic regression\", \"multinomial naive bayes\", \"support vector machine\", \"random forest\", \"knn\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Feature extraction method\n",
    "    if feature_extraction_method == \"bow\":\n",
    "        vectorizer = CountVectorizer(stop_words=stop_words, ngram_range=ngram_range)\n",
    "    if feature_extraction_method == \"tfidf\":\n",
    "        vectorizer = TfidfVectorizer(stop_words=stop_words, ngram_range=ngram_range)\n",
    "    \n",
    "    # Lemmatization\n",
    "    if lemmatization:\n",
    "        X = vectorizer.fit_transform(X_preprocessed_lemmatized)\n",
    "    else:\n",
    "        X = vectorizer.fit_transform(X_preprocessed)\n",
    "    \n",
    "    # Annotator\n",
    "    if annotator == \"final\":\n",
    "        y = y_final\n",
    "    if annotator == \"all\":\n",
    "        y = y_all\n",
    "    \n",
    "    # Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=530)\n",
    "    \n",
    "    # Classifier\n",
    "    if classifier == \"logistic regression\":\n",
    "        model = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "    if classifier == \"multinomial naive bayes\":\n",
    "        model = MultinomialNB().fit(X_train, y_train)\n",
    "    if classifier == \"support vector machine\":\n",
    "        model = SVC().fit(X_train, y_train)\n",
    "    if classifier == \"random forest\":\n",
    "        model = RandomForestClassifier().fit(X_train, y_train)\n",
    "    if classifier == \"knn\":\n",
    "        model = KNeighborsClassifier().fit(X_train, y_train)\n",
    "    \n",
    "        \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return f1_score(y_test, y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "631aeba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction_methods = [\"bow\", \"tfidf\"]\n",
    "ngram_ranges = [(1, 1), (1, 2), (1, 3), (2, 2), (2, 3), (3, 3)]\n",
    "lemmatizations = [True, False]\n",
    "annotators = [\"final\", \"all\"]\n",
    "classifiers = [\"logistic regression\", \"multinomial naive bayes\", \"support vector machine\", \"random forest\", \"knn\"]\n",
    "\n",
    "num_combinations = np.prod([len(item) for item in [feature_extraction_methods, ngram_ranges, lemmatizations, annotators, classifiers]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "127dbf3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/240- bow | (1, 1) | True | final | logistic regression | F-1 Score: 0.8784\n",
      "2/240- bow | (1, 1) | True | final | multinomial naive bayes | F-1 Score: 0.8429\n",
      "3/240- bow | (1, 1) | True | final | support vector machine | F-1 Score: 0.8568\n",
      "4/240- bow | (1, 1) | True | final | random forest | F-1 Score: 0.8704\n",
      "5/240- bow | (1, 1) | True | final | knn | F-1 Score: 0.8451\n",
      "6/240- bow | (1, 1) | True | all | logistic regression | F-1 Score: 0.8677\n",
      "7/240- bow | (1, 1) | True | all | multinomial naive bayes | F-1 Score: 0.8314\n",
      "8/240- bow | (1, 1) | True | all | support vector machine | F-1 Score: 0.8445\n",
      "9/240- bow | (1, 1) | True | all | random forest | F-1 Score: 0.8568\n",
      "10/240- bow | (1, 1) | True | all | knn | F-1 Score: 0.8316\n",
      "11/240- bow | (1, 1) | False | final | logistic regression | F-1 Score: 0.8694\n",
      "12/240- bow | (1, 1) | False | final | multinomial naive bayes | F-1 Score: 0.8456\n",
      "13/240- bow | (1, 1) | False | final | support vector machine | F-1 Score: 0.8520\n",
      "14/240- bow | (1, 1) | False | final | random forest | F-1 Score: 0.8658\n",
      "15/240- bow | (1, 1) | False | final | knn | F-1 Score: 0.8407\n",
      "16/240- bow | (1, 1) | False | all | logistic regression | F-1 Score: 0.8574\n",
      "17/240- bow | (1, 1) | False | all | multinomial naive bayes | F-1 Score: 0.8334\n",
      "18/240- bow | (1, 1) | False | all | support vector machine | F-1 Score: 0.8389\n",
      "19/240- bow | (1, 1) | False | all | random forest | F-1 Score: 0.8540\n",
      "20/240- bow | (1, 1) | False | all | knn | F-1 Score: 0.8267\n",
      "21/240- bow | (1, 2) | True | final | logistic regression | F-1 Score: 0.8747\n",
      "22/240- bow | (1, 2) | True | final | multinomial naive bayes | F-1 Score: 0.8460\n",
      "23/240- bow | (1, 2) | True | final | support vector machine | F-1 Score: 0.8494\n",
      "24/240- bow | (1, 2) | True | final | random forest | F-1 Score: 0.8570\n",
      "25/240- bow | (1, 2) | True | final | knn | F-1 Score: 0.8397\n",
      "26/240- bow | (1, 2) | True | all | logistic regression | F-1 Score: 0.8636\n",
      "27/240- bow | (1, 2) | True | all | multinomial naive bayes | F-1 Score: 0.8330\n",
      "28/240- bow | (1, 2) | True | all | support vector machine | F-1 Score: 0.8357\n",
      "29/240- bow | (1, 2) | True | all | random forest | F-1 Score: 0.8453\n",
      "30/240- bow | (1, 2) | True | all | knn | F-1 Score: 0.8257\n",
      "31/240- bow | (1, 2) | False | final | logistic regression | F-1 Score: 0.8626\n",
      "32/240- bow | (1, 2) | False | final | multinomial naive bayes | F-1 Score: 0.8305\n",
      "33/240- bow | (1, 2) | False | final | support vector machine | F-1 Score: 0.8449\n",
      "34/240- bow | (1, 2) | False | final | random forest | F-1 Score: 0.8553\n",
      "35/240- bow | (1, 2) | False | final | knn | F-1 Score: 0.8383\n",
      "36/240- bow | (1, 2) | False | all | logistic regression | F-1 Score: 0.8527\n",
      "37/240- bow | (1, 2) | False | all | multinomial naive bayes | F-1 Score: 0.8236\n",
      "38/240- bow | (1, 2) | False | all | support vector machine | F-1 Score: 0.8306\n",
      "39/240- bow | (1, 2) | False | all | random forest | F-1 Score: 0.8482\n",
      "40/240- bow | (1, 2) | False | all | knn | F-1 Score: 0.8243\n",
      "41/240- bow | (1, 3) | True | final | logistic regression | F-1 Score: 0.8702\n",
      "42/240- bow | (1, 3) | True | final | multinomial naive bayes | F-1 Score: 0.8439\n",
      "43/240- bow | (1, 3) | True | final | support vector machine | F-1 Score: 0.8446\n",
      "44/240- bow | (1, 3) | True | final | random forest | F-1 Score: 0.8550\n",
      "45/240- bow | (1, 3) | True | final | knn | F-1 Score: 0.8384\n",
      "46/240- bow | (1, 3) | True | all | logistic regression | F-1 Score: 0.8606\n",
      "47/240- bow | (1, 3) | True | all | multinomial naive bayes | F-1 Score: 0.8324\n",
      "48/240- bow | (1, 3) | True | all | support vector machine | F-1 Score: 0.8309\n",
      "49/240- bow | (1, 3) | True | all | random forest | F-1 Score: 0.8420\n",
      "50/240- bow | (1, 3) | True | all | knn | F-1 Score: 0.8245\n",
      "51/240- bow | (1, 3) | False | final | logistic regression | F-1 Score: 0.8579\n",
      "52/240- bow | (1, 3) | False | final | multinomial naive bayes | F-1 Score: 0.7700\n",
      "53/240- bow | (1, 3) | False | final | support vector machine | F-1 Score: 0.8424\n",
      "54/240- bow | (1, 3) | False | final | random forest | F-1 Score: 0.8521\n",
      "55/240- bow | (1, 3) | False | final | knn | F-1 Score: 0.8381\n",
      "56/240- bow | (1, 3) | False | all | logistic regression | F-1 Score: 0.8481\n",
      "57/240- bow | (1, 3) | False | all | multinomial naive bayes | F-1 Score: 0.7634\n",
      "58/240- bow | (1, 3) | False | all | support vector machine | F-1 Score: 0.8287\n",
      "59/240- bow | (1, 3) | False | all | random forest | F-1 Score: 0.8394\n",
      "60/240- bow | (1, 3) | False | all | knn | F-1 Score: 0.8241\n",
      "61/240- bow | (2, 2) | True | final | logistic regression | F-1 Score: 0.8479\n",
      "62/240- bow | (2, 2) | True | final | multinomial naive bayes | F-1 Score: 0.6707\n",
      "63/240- bow | (2, 2) | True | final | support vector machine | F-1 Score: 0.8403\n",
      "64/240- bow | (2, 2) | True | final | random forest | F-1 Score: 0.8495\n",
      "65/240- bow | (2, 2) | True | final | knn | F-1 Score: 0.8378\n",
      "66/240- bow | (2, 2) | True | all | logistic regression | F-1 Score: 0.8339\n",
      "67/240- bow | (2, 2) | True | all | multinomial naive bayes | F-1 Score: 0.6643\n",
      "68/240- bow | (2, 2) | True | all | support vector machine | F-1 Score: 0.8263\n",
      "69/240- bow | (2, 2) | True | all | random forest | F-1 Score: 0.8360\n",
      "70/240- bow | (2, 2) | True | all | knn | F-1 Score: 0.8238\n",
      "71/240- bow | (2, 2) | False | final | logistic regression | F-1 Score: 0.8458\n",
      "72/240- bow | (2, 2) | False | final | multinomial naive bayes | F-1 Score: 0.5851\n",
      "73/240- bow | (2, 2) | False | final | support vector machine | F-1 Score: 0.8401\n",
      "74/240- bow | (2, 2) | False | final | random forest | F-1 Score: 0.8479\n",
      "75/240- bow | (2, 2) | False | final | knn | F-1 Score: 0.8378\n",
      "76/240- bow | (2, 2) | False | all | logistic regression | F-1 Score: 0.8323\n",
      "77/240- bow | (2, 2) | False | all | multinomial naive bayes | F-1 Score: 0.5813\n",
      "78/240- bow | (2, 2) | False | all | support vector machine | F-1 Score: 0.8261\n",
      "79/240- bow | (2, 2) | False | all | random forest | F-1 Score: 0.8329\n",
      "80/240- bow | (2, 2) | False | all | knn | F-1 Score: 0.8238\n",
      "81/240- bow | (2, 3) | True | final | logistic regression | F-1 Score: 0.8458\n",
      "82/240- bow | (2, 3) | True | final | multinomial naive bayes | F-1 Score: 0.4252\n",
      "83/240- bow | (2, 3) | True | final | support vector machine | F-1 Score: 0.8382\n",
      "84/240- bow | (2, 3) | True | final | random forest | F-1 Score: 0.8485\n",
      "85/240- bow | (2, 3) | True | final | knn | F-1 Score: 0.8372\n",
      "86/240- bow | (2, 3) | True | all | logistic regression | F-1 Score: 0.8317\n",
      "87/240- bow | (2, 3) | True | all | multinomial naive bayes | F-1 Score: 0.4228\n",
      "88/240- bow | (2, 3) | True | all | support vector machine | F-1 Score: 0.8242\n",
      "89/240- bow | (2, 3) | True | all | random forest | F-1 Score: 0.8351\n",
      "90/240- bow | (2, 3) | True | all | knn | F-1 Score: 0.8233\n",
      "91/240- bow | (2, 3) | False | final | logistic regression | F-1 Score: 0.8434\n",
      "92/240- bow | (2, 3) | False | final | multinomial naive bayes | F-1 Score: 0.3389\n",
      "93/240- bow | (2, 3) | False | final | support vector machine | F-1 Score: 0.8382\n",
      "94/240- bow | (2, 3) | False | final | random forest | F-1 Score: 0.8461\n",
      "95/240- bow | (2, 3) | False | final | knn | F-1 Score: 0.8369\n",
      "96/240- bow | (2, 3) | False | all | logistic regression | F-1 Score: 0.8294\n",
      "97/240- bow | (2, 3) | False | all | multinomial naive bayes | F-1 Score: 0.3375\n",
      "98/240- bow | (2, 3) | False | all | support vector machine | F-1 Score: 0.8242\n",
      "99/240- bow | (2, 3) | False | all | random forest | F-1 Score: 0.8321\n",
      "100/240- bow | (2, 3) | False | all | knn | F-1 Score: 0.8229\n",
      "101/240- bow | (3, 3) | True | final | logistic regression | F-1 Score: 0.8400\n",
      "102/240- bow | (3, 3) | True | final | multinomial naive bayes | F-1 Score: 0.5661\n",
      "103/240- bow | (3, 3) | True | final | support vector machine | F-1 Score: 0.8366\n",
      "104/240- bow | (3, 3) | True | final | random forest | F-1 Score: 0.8438\n",
      "105/240- bow | (3, 3) | True | final | knn | F-1 Score: 0.8367\n",
      "106/240- bow | (3, 3) | True | all | logistic regression | F-1 Score: 0.8260\n",
      "107/240- bow | (3, 3) | True | all | multinomial naive bayes | F-1 Score: 0.5618\n",
      "108/240- bow | (3, 3) | True | all | support vector machine | F-1 Score: 0.8227\n",
      "109/240- bow | (3, 3) | True | all | random forest | F-1 Score: 0.8301\n",
      "110/240- bow | (3, 3) | True | all | knn | F-1 Score: 0.8227\n",
      "111/240- bow | (3, 3) | False | final | logistic regression | F-1 Score: 0.8388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/240- bow | (3, 3) | False | final | multinomial naive bayes | F-1 Score: 0.5445\n",
      "113/240- bow | (3, 3) | False | final | support vector machine | F-1 Score: 0.8364\n",
      "114/240- bow | (3, 3) | False | final | random forest | F-1 Score: 0.8428\n",
      "115/240- bow | (3, 3) | False | final | knn | F-1 Score: 0.8367\n",
      "116/240- bow | (3, 3) | False | all | logistic regression | F-1 Score: 0.8247\n",
      "117/240- bow | (3, 3) | False | all | multinomial naive bayes | F-1 Score: 0.5412\n",
      "118/240- bow | (3, 3) | False | all | support vector machine | F-1 Score: 0.8224\n",
      "119/240- bow | (3, 3) | False | all | random forest | F-1 Score: 0.8290\n",
      "120/240- bow | (3, 3) | False | all | knn | F-1 Score: 0.8227\n",
      "121/240- tfidf | (1, 1) | True | final | logistic regression | F-1 Score: 0.8613\n",
      "122/240- tfidf | (1, 1) | True | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "123/240- tfidf | (1, 1) | True | final | support vector machine | F-1 Score: 0.8565\n",
      "124/240- tfidf | (1, 1) | True | final | random forest | F-1 Score: 0.8644\n",
      "125/240- tfidf | (1, 1) | True | final | knn | F-1 Score: 0.8406\n",
      "126/240- tfidf | (1, 1) | True | all | logistic regression | F-1 Score: 0.8487\n",
      "127/240- tfidf | (1, 1) | True | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "128/240- tfidf | (1, 1) | True | all | support vector machine | F-1 Score: 0.8445\n",
      "129/240- tfidf | (1, 1) | True | all | random forest | F-1 Score: 0.8524\n",
      "130/240- tfidf | (1, 1) | True | all | knn | F-1 Score: 0.8266\n",
      "131/240- tfidf | (1, 1) | False | final | logistic regression | F-1 Score: 0.8488\n",
      "132/240- tfidf | (1, 1) | False | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "133/240- tfidf | (1, 1) | False | final | support vector machine | F-1 Score: 0.8484\n",
      "134/240- tfidf | (1, 1) | False | final | random forest | F-1 Score: 0.8596\n",
      "135/240- tfidf | (1, 1) | False | final | knn | F-1 Score: 0.8383\n",
      "136/240- tfidf | (1, 1) | False | all | logistic regression | F-1 Score: 0.8354\n",
      "137/240- tfidf | (1, 1) | False | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "138/240- tfidf | (1, 1) | False | all | support vector machine | F-1 Score: 0.8347\n",
      "139/240- tfidf | (1, 1) | False | all | random forest | F-1 Score: 0.8468\n",
      "140/240- tfidf | (1, 1) | False | all | knn | F-1 Score: 0.8244\n",
      "141/240- tfidf | (1, 2) | True | final | logistic regression | F-1 Score: 0.8506\n",
      "142/240- tfidf | (1, 2) | True | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "143/240- tfidf | (1, 2) | True | final | support vector machine | F-1 Score: 0.8485\n",
      "144/240- tfidf | (1, 2) | True | final | random forest | F-1 Score: 0.8554\n",
      "145/240- tfidf | (1, 2) | True | final | knn | F-1 Score: 0.8381\n",
      "146/240- tfidf | (1, 2) | True | all | logistic regression | F-1 Score: 0.8368\n",
      "147/240- tfidf | (1, 2) | True | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "148/240- tfidf | (1, 2) | True | all | support vector machine | F-1 Score: 0.8351\n",
      "149/240- tfidf | (1, 2) | True | all | random forest | F-1 Score: 0.8404\n",
      "150/240- tfidf | (1, 2) | True | all | knn | F-1 Score: 0.8241\n",
      "151/240- tfidf | (1, 2) | False | final | logistic regression | F-1 Score: 0.8448\n",
      "152/240- tfidf | (1, 2) | False | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "153/240- tfidf | (1, 2) | False | final | support vector machine | F-1 Score: 0.8430\n",
      "154/240- tfidf | (1, 2) | False | final | random forest | F-1 Score: 0.8552\n",
      "155/240- tfidf | (1, 2) | False | final | knn | F-1 Score: 0.8377\n",
      "156/240- tfidf | (1, 2) | False | all | logistic regression | F-1 Score: 0.8308\n",
      "157/240- tfidf | (1, 2) | False | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "158/240- tfidf | (1, 2) | False | all | support vector machine | F-1 Score: 0.8290\n",
      "159/240- tfidf | (1, 2) | False | all | random forest | F-1 Score: 0.8431\n",
      "160/240- tfidf | (1, 2) | False | all | knn | F-1 Score: 0.8238\n",
      "161/240- tfidf | (1, 3) | True | final | logistic regression | F-1 Score: 0.8455\n",
      "162/240- tfidf | (1, 3) | True | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "163/240- tfidf | (1, 3) | True | final | support vector machine | F-1 Score: 0.8422\n",
      "164/240- tfidf | (1, 3) | True | final | random forest | F-1 Score: 0.8529\n",
      "165/240- tfidf | (1, 3) | True | final | knn | F-1 Score: 0.8378\n",
      "166/240- tfidf | (1, 3) | True | all | logistic regression | F-1 Score: 0.8321\n",
      "167/240- tfidf | (1, 3) | True | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "168/240- tfidf | (1, 3) | True | all | support vector machine | F-1 Score: 0.8288\n",
      "169/240- tfidf | (1, 3) | True | all | random forest | F-1 Score: 0.8369\n",
      "170/240- tfidf | (1, 3) | True | all | knn | F-1 Score: 0.8238\n",
      "171/240- tfidf | (1, 3) | False | final | logistic regression | F-1 Score: 0.8413\n",
      "172/240- tfidf | (1, 3) | False | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "173/240- tfidf | (1, 3) | False | final | support vector machine | F-1 Score: 0.8411\n",
      "174/240- tfidf | (1, 3) | False | final | random forest | F-1 Score: 0.8494\n",
      "175/240- tfidf | (1, 3) | False | final | knn | F-1 Score: 0.8378\n",
      "176/240- tfidf | (1, 3) | False | all | logistic regression | F-1 Score: 0.8276\n",
      "177/240- tfidf | (1, 3) | False | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "178/240- tfidf | (1, 3) | False | all | support vector machine | F-1 Score: 0.8271\n",
      "179/240- tfidf | (1, 3) | False | all | random forest | F-1 Score: 0.8389\n",
      "180/240- tfidf | (1, 3) | False | all | knn | F-1 Score: 0.8238\n",
      "181/240- tfidf | (2, 2) | True | final | logistic regression | F-1 Score: 0.8398\n",
      "182/240- tfidf | (2, 2) | True | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "183/240- tfidf | (2, 2) | True | final | support vector machine | F-1 Score: 0.8408\n",
      "184/240- tfidf | (2, 2) | True | final | random forest | F-1 Score: 0.8495\n",
      "185/240- tfidf | (2, 2) | True | final | knn | F-1 Score: 0.8378\n",
      "186/240- tfidf | (2, 2) | True | all | logistic regression | F-1 Score: 0.8258\n",
      "187/240- tfidf | (2, 2) | True | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "188/240- tfidf | (2, 2) | True | all | support vector machine | F-1 Score: 0.8268\n",
      "189/240- tfidf | (2, 2) | True | all | random forest | F-1 Score: 0.8373\n",
      "190/240- tfidf | (2, 2) | True | all | knn | F-1 Score: 0.8238\n",
      "191/240- tfidf | (2, 2) | False | final | logistic regression | F-1 Score: 0.8395\n",
      "192/240- tfidf | (2, 2) | False | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "193/240- tfidf | (2, 2) | False | final | support vector machine | F-1 Score: 0.8399\n",
      "194/240- tfidf | (2, 2) | False | final | random forest | F-1 Score: 0.8459\n",
      "195/240- tfidf | (2, 2) | False | final | knn | F-1 Score: 0.8378\n",
      "196/240- tfidf | (2, 2) | False | all | logistic regression | F-1 Score: 0.8256\n",
      "197/240- tfidf | (2, 2) | False | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "198/240- tfidf | (2, 2) | False | all | support vector machine | F-1 Score: 0.8259\n",
      "199/240- tfidf | (2, 2) | False | all | random forest | F-1 Score: 0.8322\n",
      "200/240- tfidf | (2, 2) | False | all | knn | F-1 Score: 0.8238\n",
      "201/240- tfidf | (2, 3) | True | final | logistic regression | F-1 Score: 0.8389\n",
      "202/240- tfidf | (2, 3) | True | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "203/240- tfidf | (2, 3) | True | final | support vector machine | F-1 Score: 0.8390\n",
      "204/240- tfidf | (2, 3) | True | final | random forest | F-1 Score: 0.8483\n",
      "205/240- tfidf | (2, 3) | True | final | knn | F-1 Score: 0.8372\n",
      "206/240- tfidf | (2, 3) | True | all | logistic regression | F-1 Score: 0.8250\n",
      "207/240- tfidf | (2, 3) | True | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "208/240- tfidf | (2, 3) | True | all | support vector machine | F-1 Score: 0.8250\n",
      "209/240- tfidf | (2, 3) | True | all | random forest | F-1 Score: 0.8343\n",
      "210/240- tfidf | (2, 3) | True | all | knn | F-1 Score: 0.8232\n",
      "211/240- tfidf | (2, 3) | False | final | logistic regression | F-1 Score: 0.8383\n",
      "212/240- tfidf | (2, 3) | False | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "213/240- tfidf | (2, 3) | False | final | support vector machine | F-1 Score: 0.8387\n",
      "214/240- tfidf | (2, 3) | False | final | random forest | F-1 Score: 0.8465\n",
      "215/240- tfidf | (2, 3) | False | final | knn | F-1 Score: 0.8373\n",
      "216/240- tfidf | (2, 3) | False | all | logistic regression | F-1 Score: 0.8244\n",
      "217/240- tfidf | (2, 3) | False | all | multinomial naive bayes | F-1 Score: 0.8224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/240- tfidf | (2, 3) | False | all | support vector machine | F-1 Score: 0.8247\n",
      "219/240- tfidf | (2, 3) | False | all | random forest | F-1 Score: 0.8311\n",
      "220/240- tfidf | (2, 3) | False | all | knn | F-1 Score: 0.8233\n",
      "221/240- tfidf | (3, 3) | True | final | logistic regression | F-1 Score: 0.8373\n",
      "222/240- tfidf | (3, 3) | True | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "223/240- tfidf | (3, 3) | True | final | support vector machine | F-1 Score: 0.8379\n",
      "224/240- tfidf | (3, 3) | True | final | random forest | F-1 Score: 0.8433\n",
      "225/240- tfidf | (3, 3) | True | final | knn | F-1 Score: 0.8373\n",
      "226/240- tfidf | (3, 3) | True | all | logistic regression | F-1 Score: 0.8233\n",
      "227/240- tfidf | (3, 3) | True | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "228/240- tfidf | (3, 3) | True | all | support vector machine | F-1 Score: 0.8239\n",
      "229/240- tfidf | (3, 3) | True | all | random forest | F-1 Score: 0.8293\n",
      "230/240- tfidf | (3, 3) | True | all | knn | F-1 Score: 0.8233\n",
      "231/240- tfidf | (3, 3) | False | final | logistic regression | F-1 Score: 0.8373\n",
      "232/240- tfidf | (3, 3) | False | final | multinomial naive bayes | F-1 Score: 0.8364\n",
      "233/240- tfidf | (3, 3) | False | final | support vector machine | F-1 Score: 0.8379\n",
      "234/240- tfidf | (3, 3) | False | final | random forest | F-1 Score: 0.8422\n",
      "235/240- tfidf | (3, 3) | False | final | knn | F-1 Score: 0.8373\n",
      "236/240- tfidf | (3, 3) | False | all | logistic regression | F-1 Score: 0.8233\n",
      "237/240- tfidf | (3, 3) | False | all | multinomial naive bayes | F-1 Score: 0.8224\n",
      "238/240- tfidf | (3, 3) | False | all | support vector machine | F-1 Score: 0.8239\n",
      "239/240- tfidf | (3, 3) | False | all | random forest | F-1 Score: 0.8292\n",
      "240/240- tfidf | (3, 3) | False | all | knn | F-1 Score: 0.8233\n",
      "\n",
      "Comparison of classification models and different settings took 1379.62 minutes.\n"
     ]
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(columns = [\"feature_extraction_method\", \"ngram_range\", \"lemmatization\", \"annotator\", \"model\", \"f1_score\"])\n",
    "\n",
    "i = 0\n",
    "\n",
    "start_time = time.time()\n",
    "for feature_extraction_method in feature_extraction_methods:\n",
    "    for ngram_range in ngram_ranges:\n",
    "        for lemmatization in lemmatizations:\n",
    "            for annotator in annotators:\n",
    "                for classifier in classifiers:\n",
    "                    print(f\"{i+1}/{num_combinations}- {feature_extraction_method} | {ngram_range} | {lemmatization} | {annotator} | {classifier} | F-1 Score: {fit_predict_score(feature_extraction_method, stop_words, ngram_range, lemmatization, annotator, classifier):.4f}\")\n",
    "                    scores_df = scores_df.append(pd.Series([feature_extraction_method,\n",
    "                                                            ngram_range,\n",
    "                                                            lemmatization,\n",
    "                                                            annotator,\n",
    "                                                            classifier,\n",
    "                                                            fit_predict_score(feature_extraction_method,\n",
    "                                                                              stop_words,\n",
    "                                                                              ngram_range,\n",
    "                                                                              lemmatization,\n",
    "                                                                              annotator,\n",
    "                                                                              classifier)],\n",
    "                                                           index=scores_df.columns),\n",
    "                                                 ignore_index=True)\n",
    "                    i = i + 1\n",
    "\n",
    "print(f\"\\nComparison of classification models and different settings took {(time.time() - start_time)/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ca37e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_extraction_method</th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>lemmatization</th>\n",
       "      <th>annotator</th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.878366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.842941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>support vector machine</td>\n",
       "      <td>0.856846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.870077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.845095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.823278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.822402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>support vector machine</td>\n",
       "      <td>0.823899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.828008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.823278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_extraction_method ngram_range lemmatization annotator  \\\n",
       "0                         bow      (1, 1)          True     final   \n",
       "1                         bow      (1, 1)          True     final   \n",
       "2                         bow      (1, 1)          True     final   \n",
       "3                         bow      (1, 1)          True     final   \n",
       "4                         bow      (1, 1)          True     final   \n",
       "..                        ...         ...           ...       ...   \n",
       "235                     tfidf      (3, 3)         False       all   \n",
       "236                     tfidf      (3, 3)         False       all   \n",
       "237                     tfidf      (3, 3)         False       all   \n",
       "238                     tfidf      (3, 3)         False       all   \n",
       "239                     tfidf      (3, 3)         False       all   \n",
       "\n",
       "                       model  f1_score  \n",
       "0        logistic regression  0.878366  \n",
       "1    multinomial naive bayes  0.842941  \n",
       "2     support vector machine  0.856846  \n",
       "3              random forest  0.870077  \n",
       "4                        knn  0.845095  \n",
       "..                       ...       ...  \n",
       "235      logistic regression  0.823278  \n",
       "236  multinomial naive bayes  0.822402  \n",
       "237   support vector machine  0.823899  \n",
       "238            random forest  0.828008  \n",
       "239                      knn  0.823278  \n",
       "\n",
       "[240 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37df879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_extraction_method</th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>lemmatization</th>\n",
       "      <th>annotator</th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>bow</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.337530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>bow</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.338942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>bow</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.422793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>bow</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.425245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>bow</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>multinomial naive bayes</td>\n",
       "      <td>0.541242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.869353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.870077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.870230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.874668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bow</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.878366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_extraction_method ngram_range lemmatization annotator  \\\n",
       "96                        bow      (2, 3)         False       all   \n",
       "91                        bow      (2, 3)         False     final   \n",
       "86                        bow      (2, 3)          True       all   \n",
       "81                        bow      (2, 3)          True     final   \n",
       "116                       bow      (3, 3)         False       all   \n",
       "..                        ...         ...           ...       ...   \n",
       "10                        bow      (1, 1)         False     final   \n",
       "3                         bow      (1, 1)          True     final   \n",
       "40                        bow      (1, 3)          True     final   \n",
       "20                        bow      (1, 2)          True     final   \n",
       "0                         bow      (1, 1)          True     final   \n",
       "\n",
       "                       model  f1_score  \n",
       "96   multinomial naive bayes  0.337530  \n",
       "91   multinomial naive bayes  0.338942  \n",
       "86   multinomial naive bayes  0.422793  \n",
       "81   multinomial naive bayes  0.425245  \n",
       "116  multinomial naive bayes  0.541242  \n",
       "..                       ...       ...  \n",
       "10       logistic regression  0.869353  \n",
       "3              random forest  0.870077  \n",
       "40       logistic regression  0.870230  \n",
       "20       logistic regression  0.874668  \n",
       "0        logistic regression  0.878366  \n",
       "\n",
       "[240 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values(\"f1_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b5d30ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.to_csv(\"data/scores_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
